{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QePJUCDdcTzw",
        "outputId": "0b921c0e-e9f1-4c11-b44b-1b12f2ba8f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m959.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import openai\n",
        "import requests"
      ],
      "metadata": {
        "id": "wmIBt5hJcXf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize OpenAI API\n",
        "\n",
        "openai.api_key = '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'\n",
        "# URL to your online CSV file containing summaries\n",
        "\n",
        "csv_url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vS1Vfhri_fn9Hd_8eLxbsxITpbinvV8gthZC1b4WEll9bR1wJE3-bjXEPfXs8q_lEj3yLkt2irTXbuM/pub?gid=1829011843&single=true&output=csv'  # Replace with your actual CSV file URL\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(csv_url)\n",
        "\n",
        "# Assuming that your CSV has a column \"Summary\" with the text summaries\n",
        "summaries = df['Summary'].tolist()\n",
        "\n",
        "# Function to generate embeddings for a list of texts\n",
        "def generate_embeddings(texts):\n",
        "    # OpenAI's embeddings endpoint expects a list of texts\n",
        "    response = openai.Embedding.create(input=texts, model=\"text-embedding-ada-002\")\n",
        "    # Extract embeddings from the response\n",
        "    embeddings = [embedding['embedding'] for embedding in response['data']]\n",
        "    return embeddings\n",
        "\n",
        "# Generate embeddings for all summaries\n",
        "all_embeddings = generate_embeddings(summaries)"
      ],
      "metadata": {
        "id": "9CL3KnQxcXmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU pinecone-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9K2OXPZcXp8",
        "outputId": "fc62e931-7fe5-4667-9b70-59b55883a2c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.0/211.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "pc = Pinecone(api_key=\"e75eb03d-b77a-473c-aef3-01d5e6e885cd\")\n",
        "index = pc.Index(\"university-summaries\")\n",
        "\n",
        "vectors_to_upsert = [{\n",
        "    \"id\": str(i),\n",
        "    \"values\": embedding,  # If embedding is already a list, you don't need to call tolist()\n",
        "    \"metadata\": {\"summary\": summary}\n",
        "} for i, (embedding, summary) in enumerate(zip(all_embeddings, summaries))]\n",
        "\n",
        "# Upsert the data into the Pinecone index\n",
        "index.upsert(vectors=vectors_to_upsert)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LWiQNRCcXsv",
        "outputId": "d00cd1f2-3803-4324-ce3e-2bd0aa0a70e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'upserted_count': 127}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\"Which university has a small student to faculty ratio, is in a midsize city and gives law degree\"]\n",
        "response1 = openai.Embedding.create(input=texts, model=\"text-embedding-ada-002\")\n",
        "embeddings = [embedding['embedding'] for embedding in response1['data']]\n"
      ],
      "metadata": {
        "id": "Y0qtWHSdcXvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an example query vector. In a real scenario, you would use a vector relevant to your specific use case.\n",
        "query_vector = embeddings[0]  # Replace with your actual query vector\n",
        "\n",
        "index.query(\n",
        "  vector= query_vector,\n",
        "  top_k=3,\n",
        "  include_values=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJlgpllPcXyf",
        "outputId": "473d54dd-0103-4d85-ee62-56f36a4b7940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'matches': [{'id': '2', 'score': 0.833443165, 'values': []},\n",
              "             {'id': '80', 'score': 0.826919377, 'values': []},\n",
              "             {'id': '12', 'score': 0.820096254, 'values': []}],\n",
              " 'namespace': '',\n",
              " 'usage': {'read_units': 5}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pinecone\n",
        "\n",
        "def retrieve_documents(query_text, model='text-embedding-ada-002', top_k=10):\n",
        "    # Generate the embedding for the query text\n",
        "    response = openai.Embedding.create(input=[query_text], model=model)\n",
        "    query_vector = response['data'][0]['embedding']\n",
        "\n",
        "    # Query the Pinecone index to find the top_k most similar documents\n",
        "    results = index.query(\n",
        "        vector=query_vector,\n",
        "        top_k=top_k,\n",
        "        include_metadata=True\n",
        "    )\n",
        "    return results['matches']\n",
        "\n",
        "def augment_query_with_documents(prompt, documents):\n",
        "    # Combine the prompt with the retrieved documents to form a new context\n",
        "    context = prompt + ' ' + ' '.join([doc['metadata']['summary'] for doc in documents])\n",
        "    return context\n",
        "\n",
        "def generate_response(context, model='gpt-3.5-turbo'):\n",
        "    # Use OpenAI's API to generate the response based on the context\n",
        "    # Note that 'v1/chat/completions' endpoint may require different parameters.\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"system\", \"content\": \"Your system message here, if any.\"},\n",
        "                  {\"role\": \"user\", \"content\": context}]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "# Example usage\n",
        "prompt = \"Which university has a small student-to-faculty ratio and offers a law program? Give me the top 10 universities names in order?\"\n",
        "# Step 1: Retrieve similar documents based on the prompt\n",
        "documents = retrieve_documents(prompt)\n",
        "\n",
        "# Step 2: Augment the query with information from the retrieved documents\n",
        "augmented_prompt = augment_query_with_documents(prompt, documents)\n",
        "\n",
        "# Step 3: Generate the final response\n",
        "final_response = generate_response(augmented_prompt)\n",
        "\n",
        "print(final_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdN6wiqncrRG",
        "outputId": "396e53c4-23b9-40fc-e4ea-c71146c27c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the information provided, the top 10 universities with a small student-to-faculty ratio and offering a law program are:\n",
            "\n",
            "1. Selma University\n",
            "2. The School of Architecture\n",
            "3. University of Arkansas at Little Rock\n",
            "4. Amridge University\n",
            "5. The University of Alabama\n",
            "6. The University of Mobile\n",
            "7. University of Arizona\n",
            "8. The University of Alabama in Huntsville\n",
            "9. University of Alabama at Birmingham\n",
            "10. University of Arkansas\n",
            "\n",
            "These universities have been listed based on their student-to-faculty ratio and the availability of a law program.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YMJw68DYcrU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i4hOgwuecrXV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}